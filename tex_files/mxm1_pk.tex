\section
[$M^X/M/1$ Queue: Expected Waiting Time]
{$M^X/M/1$ Queue: Expected Waiting Time}
\label{sec:mxm1-queue:-expected}

It is not always the case that jobs arrive in single units, they can
also arrive as batches. For instance, cars and busses arrive at a fast
food restaurant so that the batch size consists of the number of
people in the vehicle.  In this section we derive a formula to compute
the expected queue length for this queueing process. 


Assume that jobs arrive as a Poisson process with rate $\lambda$ and
each \emph{job} contains multiple \emph{items}.  Let $A_k$ be the
arrival time of job $k$ and $A(t)$ the number of job arrivals up to
time $t$. Denote by $B_k$ the number of items that job $k$ brings into
the system.  We assume that $\{B_i\}$ is an i.i.d. sequence of
discrete random variables distributed as a generic random variable $B$
such that $\P{B = k} = f(k)$, where $f(k)$ is a given set of
probabilities. We write
\begin{equation*}
  G(k) = \P{B>k} = \sum_{m=k+1}^\infty f(m),
\end{equation*}
for the \emph{survivor function} of $B$.  We also assume that the
service time of each item is exponentially distributed with average
$1/\mu$. This queueing situation denoted by the symbol $M^X/M/1$.

The first criterion we must check for the $M^X/M/1$ queue is the
stability: the service rate must be larger than the arrival rate of
work. To determine the latter, the total number of items $N(t)$
arrived up to time $t$ must be equal to the number of arrivals $A(t)$
up to time $t$ times the batch size of each arrival, i.e.,
\begin{equation*}
N(t)=  \sum_{k=0}^\infty B_k \1{A_k \leq t} = \sum_{i=k}^{A(t)} B_k.
\end{equation*}
The (stochastic) process $\{N(t)\}$ is known as the \recall{compound
  Poisson process}. Clearly, the rate at which items arrive is,
approximately,
\begin{equation*}
  \frac{N(t)}t = \frac{A(t)}t \frac1{A(t)}\sum_{i=k}^{A(t)} B_k.
\end{equation*}
As in  the limit $A(t)/t \to \lambda$ and $(A(t))^{-1}\sum_{i=k}^{A(t)} B_k \to \E{B}$, we see that
\begin{align*}
\frac{N(t)}t \to \lambda \E B.
\end{align*}
Thus, for stability, it is necessary that the service rate
$\mu=1/\E S$ for items is larger than the rate at which items
arrive. Hence we require that the load is such that
\begin{equation*}
\rho = \lambda \E B \E S = \frac{\lambda \E B} \mu < 1.
\end{equation*}

For the average waiting time, we can use the derivation of
$\E{W_Q}=\E{S_r}/(1-\rho)$ of Section~\ref{sec:some-usef-ident} for
inspiration. Suppose a batch finds $\E{L}$ items in the system upon
arrival. Then the expected time the job spends in queue is
\begin{equation*}
  \E{W_{Q,b}} = \E{L} \E S;
\end{equation*}
\nvf{Is this true? How about the item currently in service. Shouldn't
  it be $\E{L_Q}\E S+ \E{S_r}$.}  note that this is not the same as
$\E{W_Q}$, which is the expected time an \emph{item} spends in queue.
If $B_r$ is the number of items of the batch currently in service
($B_r=0$ is the server is idle), and $L_{Q,b}$ the number of batches
in queue, then
\begin{equation*}
  \E{L} = \E{L_{Q,b}}\E B + \E{B_r}.
\end{equation*}
With  Little's law, $\E{L_{Q,b}} = \lambda \E{W_{Q,b}}$, hence
\begin{equation*}
  \E{W_{Q,b}} = \lambda \E S \E B \E{L_{Q,b}} + \E S \E{B_r},
\end{equation*}
hence,
\begin{equation*}
  \E{W_{Q,b}} = \frac{\E S}{1-\rho}\E{B_r}.
\end{equation*}
And then, from the first equation, 
\begin{equation*}
  \E{L} = \frac{\E{W_{Q,b}}}{\E S} = \frac{\E{B_r}}{1-\rho}.
\end{equation*}
Below we prove that 
\begin{equation}\label{eq:br}
  \E{B_r} = \rho\frac{\E{B^2}}{2\E B} + \frac\rho2.
\end{equation}
In Exercise~\ref{q:batch} below we rewrite this to
\begin{equation}\label{eq:43}
\E{L}  = \frac{\E{B_r}}{1-\rho} = \frac{1+C_s^2}2 \frac{\rho}{1-\rho} \E B + \frac12\frac\rho{1-\rho},
\end{equation}
where
\begin{equation*}
C_s^2 = \frac{\V B}{(\E B)^2},
\end{equation*}
is the square coefficient of variation of the batch sizes.  Observe
that this is nearly the same as $M/G/1$ waiting time
formula~\ref{eq:710}, a result we derive in Section~\ref{sec:mg1}. 

Thus, to compute the average number of items in the system, we only
need to know the first and second moment (or the variance) of the
batch size $B$. Thus, no matter how `complicated' the distribution of
$B$, when its second moment exists, the average queue length and
waiting time can be computed with the above result. 



\begin{figure}[t]
  \centering
  \begin{tikzpicture}[scale=0.8,
  open/.style={shape=circle, fill=white, inner sep=1pt, draw, node contents=},
  closed/.style={shape=circle, fill=black, inner sep=1pt, draw, node contents=}]

    % y = zero line
    \draw (-0.5, 0) -- (18.5, 0); 

    \draw node (c1) at (0,3) [closed, label={}]
          node (c2) at (3,0)[open, label={}]
     (c1) to (c2);
    \draw[dotted] (0,0) -- (0,3) node[midway, fill=white] {$B_1$};


    \draw node (c1) at (3,2) [closed, label={}]
          node (c2) at (5,0)[open, label={}]
     (c1) to (c2);
    \draw[dotted] (3,0.1) -- (3,2) node[midway, fill=white] {$B_2$};

    \draw node (c1) at (5,4) [closed, label={}]
          node (c2) at (9,0)[open, label={}]
     (c1) to (c2);
    \draw[dotted] (5,0.1) -- (5,4) node[midway, fill=white] {$B_3$};
    \draw[dotted] (6,0.1) -- (6,3) node[midway, fill=white] {$R$};

    \draw node (c1) at (9,2.3) [closed, label={}]
          node (c2) at (11.3,0)[open, label={}]
     (c1) to (c2);
    \draw[dotted] (9,0.1) -- (9,2.3) node[midway, fill=white] {$B_4$};

    % end
    \draw node (c1) at (15,3) [closed, label={}]
          node (c2) at (18,0)[open, label={}]
     (c1) to (c2);
    \draw[dotted] (15,0.1) -- (15,3) node[midway, fill=white ] {$B_n$};
    
    % level crossing
    \draw (-0.5, 2.5) -- (18.5, 2.5) 
    node[pos=0.65, fill=white]
    {$\sum_{k=1}^n \1{B_k \geq i}$};
    \draw[<->] (14., 0) -- (14., 2.5) node[fill=white, midway, rotate=90] {$i$};


    % bottom line
    \draw[<->] (0, -0.6) -- (18, -.6) node[fill=white, midway] {$\sum_{k=1}^n B_k$};


\end{tikzpicture}

\caption{The remaining job size as a function of time.}
  \label{fig:remainingservicetime}
\end{figure}


We now turn to proving~\eqref{eq:br} with sample-path arguments and
counting; its an elegant line of reasoning. First concentrate on the
time the server is busy, i.e., just remove all idle times, and plot
the remaining job size during the service of the job, c.f,
Figure~\ref{fig:remainingservicetime}. Second, define $R$ as the
remaining number of items to be served of the job in service at some
arbitrary point in time. Let us show that
\begin{equation*}
  \P{R=i} =\frac{\P{B\geq i}}{\E B} = \frac{G(i-1)}{\E B}.
\end{equation*}
In Figure~\ref{fig:remainingservicetime} concentrate on level
$i$. Only jobs whose initial batch size is larger or equal to~$i$ will
produce, during its service, a remaining number of items equal to $i$.
Thus, by counting, we see in Figure~\ref{fig:remainingservicetime}
that $\sum_{k=1}^n \1{B_k \geq i}$ is the number of times there are
precisely $i$ remaining items.  We also see  that
$\sum_{k=1}^n B_k$ is the total time the server is busy. Thus, the
probability that an arbitrary arrival sees $i$ remaining items in
service is $\sum_{k=1}^n \1{B_k \geq i}/\sum_{k=1}^n B_k$, where we
use PASTA to conclude that any item of the $\sum_{k} B_k$ items is
`chosen' with the same probability.  Assuming that the limits exist,
\begin{equation*}
  \frac{n^{-1}\sum_{k=1}^n \1{B_k \geq i}}{n^{-1}\sum_{k=1}^n B_k} \to \frac{G(i-1)}{\E B} = \P{R=i}, \quad \text{as  } n\to\infty.
\end{equation*}

With this expression for $\P{R=i}$, the expected remaining time becomes
\begin{equation*}
  \begin{split}
  \E{R} 
&= \sum_{i=1}^\infty i \P{R=i} = \sum_{i=1}^\infty i \frac{G(i-1)}{\E B} \\
&=\sum_{i=0}^\infty (i+1) \frac{G(i)}{\E B} 
=\sum_{i=0}^\infty i \frac{G(i)}{\E B} +
\sum_{i=0}^\infty \frac{G(i)}{\E B}\\
&= \frac{\E{B^2}}{2\E B} - \frac{\E B}{2\E B} + \frac{\E B}{\E B} = \frac{\E{B^2}}{2\E B} + \frac{1}2,
  \end{split}
\end{equation*}
where we use the results of the exercises below.

Finally, recalling that in the above we conditioned on the server
being busy, we get that $\E{B_r} = \rho \E R$.  Combining this with
the above expression we obtain~\eqref{eq:br}.

\begin{remark}
  The above derivation for $\P{R=i}$ is important for its own sake. It
  is known as the \emph{remaining lifetime distribution} or the
  \emph{residual life}. It is worth remembering, in particular the
  sample path derivation. 
\end{remark}

\begin{question}
  Why is $\rho = \lambda \E B \E S$ the appropriate definition
  of load for the $M^X/M/1$ queue?
  \begin{solution}
    Jobs arrive at rate $\lambda$. The average number of items per job
    is $\E B$. Hence, work arrives as rate $\lambda \E B \E S$.This
    rate must be less than 1 for stability.
  \end{solution}
\end{question}

\begin{question}
  Relate $f(k)$, the distribution $F(k)$ of the batch size $B$ and the
  survivor function~$G$. Which of the three alternatives is true:
  $G(k) = 1-F(k)$, $G(k) = 1-F(k-1)$, $G(k) = 1-F(k+1)$?
\hint{ This exercise is just meant to become familiar with the notation.}
  \begin{solution}
    \begin{align*}
    f(k) &= \P{B=k} = \P{B\leq k} - \P{B\leq k-1} = F(k)-F(k-1), \\
    G(k) &= \P{B>k} = 1 - \P{B\leq k} = 1-F(k).        
    \end{align*}
    It is all too easy to make, so called, off-by-one errors, such as
    in the three alternatives above.  I nearly always check simple
    cases to prevent such simple mistakes. I advise you to acquire the
    same habit.
  \end{solution}
\end{question}

\begin{question}
  A common operational problem is a machine that receives batches of
  various sizes. Management likes to know how a reduction of the
  variability of the batch sizes affects the average queueing time.
  Suppose, for the sake of an example, that the batch size $B=1,2,$ or
  $3$, with equal probability. Batches arrive at rate 1 per hour. The
  average processing for an item is $25$ minutes.  How much does the
  waiting time decrease if batch sizes are $2$ always?

  \begin{solution}
    Start with the simple case, $B\equiv 2$. Then $\V{B}=0$ and
    $\E B = 2$. The load is $\rho=\lambda \E B \E S = 1\cdot 2 \cdot 25/60 = 5/6$.  hence,
    \begin{equation*}
      \E{L} = \frac 12 \frac{5/6}{1/6} 2 + \frac 12 \frac{5/6}{1/6} = 5 + \frac52.
    \end{equation*}

Now the other case. $\E{B^2} = (1+4+9)/3 = 14/3$. Hence, $\V B=14/3 - 4=2/3$. Hence, 
\begin{equation*}
C_s^2=\frac{\V B}{(\E B)^2} = \frac{2/3}4 = \frac 16.
\end{equation*}
And thus, 
    \begin{equation*}
      \E{L} = \frac {1+1/6}2 \frac{5/6}{1/6} 2 + \frac 12 \frac{5/6}{1/6} = \frac76 5 + \frac 52.
    \end{equation*}
    If we devide these two answers, we see that the ratio between
    $\E{L}$ for both answers is $10/9$. In other words, we can
    reduce about 10\% of the number of items in the system by working
    in fixed batch sizes. 

    Observe how easy it is with these models to get insight into the
    order of magnitude that can be achieved with changing work habits,
    such as working in contant batch sizes. 

    Observe also that its up to management to decide whether this
    reduction outweighs any efforts to reduce the variation in batch
    sizes. (In our model we assume that $B=2$, i.e., we removed all
    variability. This is the best possible. Real life reductions will
    typically achieve less than the 10\% reduction.)
  \end{solution}
\end{question}

\begin{question}
  In a production enviroment, a machine replenishes an inventory of
  items (e.g., hamburgers) at a fixed rate of $1$ per 3 minutes. If
  the inventory reaches some level $r$, the machine stops.  Customers
  arrive at rate of 6 per hour. A customer can buy items in different
  quanties, $B=1,2,3,4$, all with equal probability. What is a
  sensible value for the stopping level $r$?  

  \hint{Realize that the inventory process $I(t)$ behaves as
    $I(t)=r-L(t)$ where $L(t)$ is a suitable queueing process.}
  \begin{solution}
    Consider a queueing system with job arrival rate $\lambda=6$ per
    hour and the jobs have batch sizes as indicated in the
    problem. The average number of items in the system  follows like this
    \begin{align*}
      \E B &= \frac{1+2+3+4}{4} = \frac 52 \\
      \E{B^2} &= \frac{1+4+9+16}{4} = \frac{30}4\\
      \V{B^2} &= \frac{30}4 - \frac{25}4 = \frac 5 4\\
      C_s^2 &= \frac{5/4}{25/4} = \frac 15\\
      \rho &= \lambda \E B \E S = 6 \frac 52 \frac 1{20} = \frac 34.
    \end{align*}
Hence, 
\begin{equation*}
  \E{L} = \frac {1+1/5}2 \frac{3/4}{1/4} \frac 52 + \frac 12 \frac{3/4}{1/4} = 6.
\end{equation*}

Thus, if the level is set to $r=4$, then on average there will be two
items short. Clearly, then, $r$ should be at least $6$. However,
$\E{L}$ is just the average. Roughly speaking, in this case half of
the demand will then be lost. So, if we take variability into account,
$r$ should be quite a bit bigger than 6. A more detailed analysis is
necessary to determine the right value of $r$ such that not more than
a certain fraction of demand is lost. We will address this issue in
Section~\ref{sec:batch-arrivals}.

    
  \end{solution}
\end{question}

\begin{question}\label{ex:6}
 Use indicator functions to prove that
    \begin{equation*}
      \sum_{n=0}^\infty G(n) = \E B.
    \end{equation*}
    \hint{
Write 
$\sum_{n=0}^\infty G(n) = \sum_{n=0}^\infty \sum_{i=n+1}^\infty \P{B=i}$ and then do the algebra.}
\begin{solution}
  Realize that this sort of problem is just a regular probability
  theory problem, nothing fancy. We use/adapt the tools you learned in
  calculus to carry out 2D integrals (or in this case 2D summations.)
\begin{align*}
\sum_{n=0}^\infty G(n) 
&= \sum_{n=0}^\infty \P{B>n} 
= \sum_{n=0}^\infty \sum_{i=n+1}^\infty \P{B=i}  \\
& = \sum_{n=0}^\infty \sum_{i=0}^\infty 1\{n<i\} \P{B=i} 
= \sum_{i=0}^\infty \sum_{n=0}^\infty 1 \{n<i\} \P{B=i} \\
&= \sum_{i=0}^\infty i \P{B=i} = \E B.
\end{align*}
In case you are interested in mathematical justifications: the
interchange of the two summations is allowed because the summands are
all positive. (Interchanging the order of summations or integration is
not allways allowed because the results can be different when part of
the integrand is negative. Check Fubini's theorem for more on this if
you are interested.)

\end{solution}
\end{question}

\begin{question}
 Use indicator functions to prove that
    \begin{equation*}
\sum_{i=0}^\infty i G(i) =  \frac{\E B^2}2 - \frac{\E B}{2}.
    \end{equation*}
\hint{$\sum_{i=0}^\infty i G(i) = \sum_{n=0}^\infty \P{B=n} \sum_{i=0}^\infty i 1\{n\geq i+1\}$.}
\begin{solution}
\begin{align*}
\sum_{i=0}^\infty i G(i)
&= \sum_{i=0}^\infty i \sum_{n=i+1}^\infty \P{B=n} = \sum_{n=0}^\infty \P{B=n} \sum_{i=0}^\infty i 1\{n\geq i+1\} \\
&= \sum_{n=0}^\infty \P{B=n} \sum_{i=0}^{n-1}i  = \sum_{n=0}^\infty \P{B=n} \frac{(n-1)n}{2} \\
&= \sum_{n=0}^\infty  \frac{n^2}{2} \P{B=n} - \frac{\E B}{2}
= \frac{\E B^2}2 - \frac{\E B}{2}.
\end{align*}
\end{solution}
\end{question}


\begin{question}
 Use indicator functions to prove that for  a continuous random
    variable $S$ with distribution function $F$, 
\begin{align*}
    \E S &= \int_0^\infty x dF  = \int_0^\infty G(y) \d y,\\
\end{align*}
where $G(x) = 1 - F(x)$. 
\hint{$\E S = \int_0^\infty x \d F  = \int_0^\infty \int_0^\infty 1_{y\leq x} \d y \d F(x)$.}
\begin{solution}
\begin{equation*}
  \begin{split}
    \E S &= \int_0^\infty x \d F  = \int_0^\infty \int_0^x \d y \d F(x) \\
    & = \int_0^\infty \int_0^\infty 1_{y\leq x} \d y \d F(x)   = \int_0^\infty \int_0^\infty 1_{y\leq x} \d F(x) \d y\\
    & = \int_0^\infty \int_y^\infty \d F(x) \d y = \int_0^\infty G(y) \d y
  \end{split}
\end{equation*}
\end{solution}
\end{question}

\begin{question}
 Use indicator functions to prove that for  a continuous random
    variable $S$ with distribution function $F$, 
\begin{align*}
    \E S^2 &= \int_0^\infty x^2 dF  = 2 \int_0^\infty y G(y) \d y,
\end{align*}
where $G(x) = 1 - F(x)$. 
\hint{$\int_0^\infty y G(y) \d y \int_0^\infty y \int_0^\infty 1\{y\leq x\}f(x)\, \d x \d y$.
}
\begin{solution}
  \begin{equation*}
    \begin{split}
\int_0^\infty y G(y) \d y 
&=  \int_0^\infty y \int_y^\infty f(x)\, \d x \d y =  \int_0^\infty y \int_0^\infty 1\{y\leq x\}f(x)\, \d x \d y\\
&=  \int_0^\infty f(x) \int_0^\infty y 1\{y \leq x\}\, \d x \d y
=  \int_0^\infty f(x) \int_0^x y\, \d x \d y\\
&=  \int_0^\infty f(x) \frac{x^2}2 \d x =\frac{\E S^2}2.
    \end{split}
  \end{equation*}
\end{solution}
\end{question}


\begin{question}
  Use that $\E S = \int_0^\infty x dF = \int_0^\infty G(y) \d y$ to
  check that  $\E S = \mu^{-1}$ if $F(x) = 1 - e^{-\mu x}$.
\begin{solution}
If $F(x) = 1 - e^{-\mu x}$, we obtain that 
\begin{equation*}
  \E S = \int_0^\infty e^{-\mu x} \d x =
  \mu^{-1}\int_0^\infty e^{-x} \d x = \mu^{-1}.
\end{equation*}
\end{solution}
\end{question}



\begin{question}\label{q:batch}
Show that 
\begin{equation*}
  \frac{\lambda}\mu \E{B^2} = \rho (1+C_s^2)\E B, 
\end{equation*}
  \begin{solution}
We have
\begin{equation*}
  \begin{split}
  \frac{\lambda}\mu \E{B^2} 
&=   \frac{\lambda\E B}{\mu} \frac{\E{B^2}}{(\E B)^2} \E B  = \rho \frac{\E{B^2}}{(\E B)^2} \E B \\
&= \rho \frac{(\E B)^2+\V B}{(\E B)^2}\E B = \rho (1+C_s^2)\E B.
  \end{split}
\end{equation*}
  \end{solution}
\end{question}

\begin{question}
  Show that the expression $\E{L(M^X/M/1)}$ reduces to
  $\E{L(M/M/1)}$ when the batch size is 1.  \hint{What is the
    distribution of the batch size $B$ for the $M/M/1$ queue?}
  \begin{solution}
    For the $M/M/1$ queue, each job contains just one item. Thus,
    $B\equiv 1$, hence $\P{B=1}=1$, $\E{B^2}=\E B =1$. Therefore,
    $\E{B_r(M/M/1)}= \rho$, and $\E{L(M/M/1)}=\rho/(1-\rho)$. 

      Such checks are always important to do. Does the new result
      reduce to the results of the models you know?
  \end{solution}

\end{question}

\begin{question}
  Compare $\E{L(M^X/M/1)}$ to $\E{L(M/M/1)}$ when the loads are the
    same. What do you conclude?

  \begin{solution}
    \begin{equation*}
    \frac{\E{L(M^X/M/1)}}{\E{L(M/M/1)}} = \frac{\E{B_r}}{\rho} = 
\frac{\E{B^2}}{2\E B} + \frac 12.
    \end{equation*}
With this we can check whether this condition
    \begin{equation*}
    1\leq \frac{\E{L(M^X/M/1)}}{\E{L(M/M/1)}} = \frac{\E{B^2}}{2\E B} + \frac 12
    \end{equation*}
    is always true. Clearly, it reduces to
\begin{equation*}
\E B \leq  \E{B^2}.
\end{equation*}
Next, we can use Jensen's inequality ($\phi(\E X) \leq \E{\phi(X)}$
when $\phi$ is convex. In this case take $\phi(x)=x^2$.) to interpret
this a bit further. First, by multiplying both sides with $\E B$ (to
get $(\E B)^2$ at the left hand side), we get
\begin{equation*}
(\E B)^2 \leq  \E{B^2} \E B.
\end{equation*}
Since $B\geq 1$ (A job minimally contains one item) we have
\begin{equation*}
  \begin{split}
(\E B)^2 
&\leq  \E{B^2}, \quad{\text{Jensen's inequality}}
\leq   \E{B^2} \E B, \quad{B \geq 1}.
  \end{split}
\end{equation*}
Clearly, these inequalities are always satisfied. Hence, 
    \begin{equation*}
    1\leq \frac{\E{L(M^X/M/1)}}{\E{L(M/M/1)}}
    \end{equation*}
for all $B$. 

In conclusion, if work arrives in batches, the average number of jobs
in the system, increases, hence the average waiting time increases.

  \end{solution}
\end{question}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../booktest"
%%% End:

